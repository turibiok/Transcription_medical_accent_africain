{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caace14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÅ Transcription audio avec Azure Whisper + Synth√®se vocale avec Bark\n",
    "!pip install -q openai python-dotenv\n",
    "!pip install -q git+https://github.com/suno-ai/bark.git\n",
    "!pip install -q scipy torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0058c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from scipy.io.wavfile import write\n",
    "from bark import SAMPLE_RATE, generate_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677c68e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Pr√©parer les dossiers\n",
    "audio_dir = Path(\"/content/audio_batch\")\n",
    "transcribed_dir = Path(\"/content/audio_synthetise\")\n",
    "audio_dir.mkdir(exist_ok=True)\n",
    "transcribed_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1d59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîê .env API config (√† remplir avec vos infos Azure)\n",
    "with open(\"/content/.env\", \"w\") as f:\n",
    "    f.write(\"\"\"AZURE_OPENAI_API_KEY=your_api_key_here\n",
    "AZURE_OPENAI_ENDPOINT=https://instancehackatonpionners05.openai.azure.com\n",
    "AZURE_OPENAI_DEPLOYMENT=gpt-4o-pionners34\n",
    "AZURE_OPENAI_API_VERSION=2024-05-01-preview\n",
    "\"\"\")\n",
    "load_dotenv(\"/content/.env\")\n",
    "\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98723df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# üîÅ Traitement de chaque fichier\n",
    "for file_path in audio_dir.glob(\"*.[wm][ap][v3]\"):\n",
    "    file_name = file_path.name\n",
    "    print(f\"üéß Traitement de : {file_name}\")\n",
    "\n",
    "    # üéôÔ∏è √âtape 1 : Transcription Whisper Azure\n",
    "    with open(file_path, \"rb\") as audio_file:\n",
    "        response = openai.Audio.transcribe(\n",
    "            file=audio_file,\n",
    "            model=\"whisper-1\",\n",
    "            deployment_id=deployment_name,\n",
    "            response_format=\"text\"\n",
    "        )\n",
    "        texte_transcrit = response.strip()\n",
    "\n",
    "    # üîä √âtape 2 : Synth√®se vocale Bark (accent africain)\n",
    "    prompt = \"African French accent, male voice. \" + texte_transcrit\n",
    "    audio_out = generate_audio(prompt)\n",
    "    out_path = transcribed_dir / f\"{file_path.stem}_bark_revoice.wav\"\n",
    "    write(out_path, SAMPLE_RATE, audio_out)\n",
    "\n",
    "    # R√©sum√©\n",
    "    results.append({\n",
    "        \"fichier_audio\": file_name,\n",
    "        \"transcription\": texte_transcrit,\n",
    "        \"audio_synthetise\": out_path.name\n",
    "    })\n",
    "\n",
    "# üíæ Sauvegarde CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"/content/resume_transcription_tts.csv\", index=False)\n",
    "print(\"‚úÖ R√©sum√© export√© dans resume_transcription_tts.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
